{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目的\n",
    "VGG16モデルを用いた転移学習をFXTFのデータに適用する。   \n",
    "[VGG16のFine-tuningによる17種類の花の分類 - 人工知能に関する断創録](http://aidiary.hatenablog.com/entry/20170131/1485864665)の次のコードを参考にする：   \n",
    "```\n",
    "# VGG16モデルと学習済み重みをロード\n",
    "# Fully-connected層（FC）はいらないのでinclude_top=False）\n",
    "input_tensor = Input(shape=(img_rows, img_cols, 3))\n",
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "# FC層を構築\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# VGG16とFCを接続\n",
    "model = Model(input=vgg16.input, output=top_model(vgg16.output))\n",
    "\n",
    "# 最後のconv層の直前までの層をfreeze\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Fine-tuningのときはSGDの方がよい\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T08:06:20.805263Z",
     "start_time": "2017-09-26T08:06:11.421810Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers, Input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPool2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import model_from_json, load_model\n",
    "from keras.optimizers import Adam, Adagrad, SGD\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import copy\n",
    "import datetime\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from FX.FX.core import utils\n",
    "# from FX.FX import KerasModelAdapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T08:06:21.076103Z",
     "start_time": "2017-09-26T08:06:20.805263Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basepath = \"C:/Users/Surpris/Desktop/20170918/\"\n",
    "basepath = \"../../images/20170918/\"\n",
    "filelist = np.array(glob.glob(os.path.join(basepath, \"images-ohlc/*.png\")))\n",
    "data = pd.read_csv(basepath + \"FXTF/USDJPY-cd1_20170806_k030.csv\")\n",
    "y = data[[\"label1\", \"label2\", \"label3\"]].as_matrix()[9:].copy()\n",
    "\n",
    "Xpath_train, Xpath_test, y_train, y_test = train_test_split(filelist, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T08:06:21.088982Z",
     "start_time": "2017-09-26T08:06:21.076103Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grpX, grpY = utils.grouping_dataset(Xpath_train, y_train, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16モデルの読み込み\n",
    "[Kerasの公式サイト（日本語版）](https://keras.io/ja/applications/#vgg16)にもあるが、VGG16は幅と高さが４８以上、チャネルが３つのデータを入れる必要がある。   \n",
    "つまり $(h, w, c) = (\\geq 48, \\geq 48, 3)$ でなくてはならない。   \n",
    "\n",
    "モデルが存在しない場合は最初に学習済みモデル（HDF5形式）のダウンロードが始まる。   \n",
    "inputのサイズが(100, 100, 3)の時にファイルサイズが56.1 MBであった。それほど大きくはない。   \n",
    "モデルのダウンロード先は`%USERPROFILE%\\.keras\\models\\`フォルダである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T08:06:56.412379Z",
     "start_time": "2017-09-26T08:06:56.398369Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = utils.load_images_from_filelist(Xpath_test[:2], channel=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T08:06:59.336724Z",
     "start_time": "2017-09-26T08:06:58.677819Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    img1\n",
    "except:\n",
    "    img1 = X_test[0]\n",
    "input_shape = img1.shape\n",
    "input_tensor = Input(shape=input_shape)\n",
    "\n",
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全結合層の構築と接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T08:07:01.018249Z",
     "start_time": "2017-09-26T08:07:00.932219Z"
    }
   },
   "outputs": [],
   "source": [
    "# 構築\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "# 接続\n",
    "model = Model(inputs=vgg16.input, outputs=top_model(vgg16.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T06:51:42.853152Z",
     "start_time": "2017-09-26T06:51:42.844129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 3)                 1180675   \n",
      "=================================================================\n",
      "Total params: 15,895,363\n",
      "Trainable params: 15,895,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fine-tuningしたい層以外をfreeze\n",
    "fine-tuningしたいのは全結合層とその手前の畳み込み層とする。  \n",
    "次の図のような感じ。   \n",
    "![](../../images/VGG16_image.webp)   \n",
    "（[Deep learningで画像認識⑧〜Kerasで畳み込みニューラルネットワーク vol.4〜 - IMACEL Academy -人工知能・画像解析の技術応用に向けて-|LPixel(エルピクセル)](https://lp-tech.net/articles/ks8F9)より引用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T08:07:04.295794Z",
     "start_time": "2017-09-26T08:07:04.253490Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最後のconv層の直前までの層をfreeze\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Fine-tuningのときはSGDの方がよい（理由は不明）\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メモリが足りないので、セルフバッチ学習を行ってみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-26T08:07:36.387Z"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "callbacks.append(EarlyStopping(monitor='val_loss', patience=1))\n",
    "\n",
    "X_fpath, ys = grpX[0], grpY[0]\n",
    "N = len(X_fpath)\n",
    "batch_size = 100\n",
    "for ii in range(N//batch_size):\n",
    "    start = ii * batch_size\n",
    "    end = (ii+1) * batch_size\n",
    "    X = utils.load_images_from_filelist(X_fpath[start:end], 3)\n",
    "    y = ys[start:end]\n",
    "    hist = model.fit(X, y, batch_size=batch_size, epochs=10,\n",
    "                     validation_split=0.1, \n",
    "                     callbacks=callbacks, verbose=0)\n",
    "    if ii == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T07:20:56.269850Z",
     "start_time": "2017-09-26T07:20:56.264103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.4444444477558136,\n",
       "  0.42222222685813904,\n",
       "  0.43333333730697632,\n",
       "  0.47777777910232544,\n",
       "  0.4444444477558136,\n",
       "  0.42222222685813904,\n",
       "  0.47777777910232544,\n",
       "  0.4444444477558136,\n",
       "  0.56666666269302368],\n",
       " 'loss': [0.99315696954727173,\n",
       "  1.0379666090011597,\n",
       "  1.0105534791946411,\n",
       "  1.0045055150985718,\n",
       "  0.99449193477630615,\n",
       "  1.016797661781311,\n",
       "  0.97113806009292603,\n",
       "  1.0045349597930908,\n",
       "  0.90805554389953613],\n",
       " 'val_acc': [0.5,\n",
       "  0.5,\n",
       "  0.40000000596046448,\n",
       "  0.40000000596046448,\n",
       "  0.40000000596046448,\n",
       "  0.40000000596046448,\n",
       "  0.40000000596046448,\n",
       "  0.5,\n",
       "  0.5],\n",
       " 'val_loss': [0.83791673183441162,\n",
       "  0.83280009031295776,\n",
       "  0.82866752147674561,\n",
       "  0.82555615901947021,\n",
       "  0.82388228178024292,\n",
       "  0.82312887907028198,\n",
       "  0.82300138473510742,\n",
       "  0.82352769374847412,\n",
       "  0.82465255260467529]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-26T08:07:58.698Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"../../images/20170918/ML/model_VGG16_2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-26T08:08:08.483Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(\"../../images/20170918/ML/model_VGG16_2.h5\")\n",
    "X_test = utils.load_images_from_filelist(Xpath_test[:6000], channel=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-26T08:08:12.690Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_probability(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-26T08:08:13.509Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.calc_accuracy_above_threshold(model, X_test, y_test[:len(X_test)], threshold=0.60, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "VGG16を用いた転移学習をFXTFのOHLC図に適用した。   \n",
    "精度が上がったような雰囲気はないことから、いまのOHLC図ではうまく予測ができないのかもしれない。   \n",
    "色を付けてみるとか、Volumeを加えてみるとか試すのもよいか？   \n",
    "もしくは、単に学習回数などが足りないか。   \n",
    "Batch normalizationを加えたときのように予測確率の変な飛びがないようだから、期待される動作はしていると思われる。\n",
    "\n",
    "VGG16を利用する際に気を付けることとして、訓練時にメモリを数GBは利用するという点か。   \n",
    "訓練用データを一度に多く与えるとメモリ使用量が増加するため、少しずつ与えて訓練するのがよいかもしれない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {
    "height": "191px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
