{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目的\n",
    "TensorflowやTheanoのラッパーである`Keras`を使う練習。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T03:07:15.078853",
     "start_time": "2017-05-28T03:07:14.980281"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from FX.FX import SQLAnaforFX\n",
    "from FX.FX import drawfigfunc as dff\n",
    "from FX.FX import analyzefuncs as af\n",
    "# from FX.FX import downloadFXdata as dFX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T03:07:16.667836",
     "start_time": "2017-05-28T03:07:16.203664"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"DBの読み込み\"\"\"\n",
    "dbpath = \"201704\"\n",
    "sql = SQLAnaforFX(dbpath)\n",
    "sql.showtablenames()\n",
    "\n",
    "\"\"\"OHLC\"\"\"\n",
    "close = sql.toDataFrame(\"ask01min\", colselect=[\"close\"]).as_matrix()[:,0]\n",
    "opens = sql.toDataFrame(\"ask01min\", colselect=[\"open\"]).as_matrix()[:,0]\n",
    "high = sql.toDataFrame(\"ask01min\", colselect=[\"high\"]).as_matrix()[:,0]\n",
    "low = sql.toDataFrame(\"ask01min\", colselect=[\"low\"]).as_matrix()[:,0]\n",
    "ohlc = np.vstack((opens, high, low, close))\n",
    "\n",
    "dclose = np.zeros_like(close)\n",
    "dclose[1:] = np.diff(close)\n",
    "\n",
    "# Calculate mean spread\n",
    "close_bid = sql.toDataFrame(\"bid01min\", colselect=[\"close\"]).as_matrix()\n",
    "s = np.mean((close - close_bid)[close != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMIの学習\n",
    "やはりBMIのデータを用いて学習させてみる。次はIrisでもテストするか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの正規化と分離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T01:22:59.753258",
     "start_time": "2017-05-25T01:22:59.640670"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BMIのデータを読み込んで正規化する --- (※1)\n",
    "csv = pd.read_csv(\"./data/bmi.csv\")\n",
    "# 体重と身長のデータ\n",
    "csv[\"weight\"] /= 100\n",
    "csv[\"height\"] /= 200\n",
    "X = csv[[\"weight\", \"height\"]].as_matrix() # --- (*1a)\n",
    "\n",
    "# ラベル\n",
    "bclass = {\"thin\":[1,0,0], \"normal\":[0,1,0], \"fat\":[0,0,1]}\n",
    "y = np.empty((20000,3))\n",
    "for i, v in enumerate(csv[\"label\"]):\n",
    "    y[i] = bclass[v]\n",
    "\n",
    "# 訓練データとテストデータを分ける --- (※2)\n",
    "train_size = 10000\n",
    "X_train, y_train = X[1:train_size + 1], y[1:train_size + 1]\n",
    "X_test,  y_test  = X[train_size + 1:], y[train_size + 1:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの構造の定義\n",
    "モデルは`Sequential`を用いて、直線的に各レイヤーの定義を追加していく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T01:27:29.640306",
     "start_time": "2017-05-25T01:27:29.467299"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの構造を定義 --- (※3)\n",
    "model = Sequential() # 初期化\n",
    "\n",
    "model.add(Dense(128, input_shape=(2,))) # 中間層の第一層。入力層？入力は\"height\"と\"weight\"の二つ\n",
    "model.add(Activation('relu')) # ReLU関数を活性化関数とする\n",
    "model.add(Dropout(0.1)) # 10%のノードをドロップアウト\n",
    "\n",
    "model.add(Dense(128)) # 第二層\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(3)) # 第三層は出力層\n",
    "model.add(Activation('softmax')) # 最後はsoftmax関数を用いてみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルのコンパイル\n",
    "この段階で損失関数などを定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T01:27:30.071387",
     "start_time": "2017-05-25T01:27:29.945285"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルを構築 --- (※4)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=\"rmsprop\",\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練\n",
    "verbose = 1 にして出力すると、Notebookへの出力の関係で止まる。なのでverbose = 0にすること。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T01:30:48.721675",
     "start_time": "2017-05-25T01:30:46.160566"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# データで訓練 --- (※5)\n",
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=100,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=2)],\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T01:30:51.237968",
     "start_time": "2017-05-25T01:30:50.786128"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 0.0458675569633\n",
      "accuracy= 0.98039803981\n"
     ]
    }
   ],
   "source": [
    "# テストデータを用いて評価する --- (※6)\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所感\n",
    "Tensorflowを直に利用するよりははるかに直感的な操作が可能であると感じられた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Irisのデータ\n",
    "sklearnのデータセットに入っているirisのデータを用いて学習の練習をしてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T02:00:47.694745",
     "start_time": "2017-05-25T02:00:47.386815"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正解ラベルの加工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T01:58:03.290774",
     "start_time": "2017-05-25T01:58:03.276766"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def labeling(target):\n",
    "    uniques = np.sort(np.unique(target))\n",
    "    size = len(uniques)\n",
    "    labels = np.zeros((len(target), size), dtype=int)\n",
    "    for ii in range(size):\n",
    "        labels[target == uniques[ii], ii] = 1\n",
    "    \n",
    "    return labels.copy()\n",
    "label = labeling(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの正規化と分離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T02:12:18.155570",
     "start_time": "2017-05-25T02:12:18.143058"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = iris.data.copy()\n",
    "X = X / np.tile((X.max(axis=0))[None, :], (len(X), 1))\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの構造の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T02:24:01.678520",
     "start_time": "2017-05-25T02:24:01.429319"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 入力層\n",
    "model.add(Dense(512, input_shape=(X.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# 中間層\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(y.shape[1]))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# コンパイル\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "    optimizer=\"rmsprop\",\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練と評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T02:24:05.100064",
     "start_time": "2017-05-25T02:24:02.469205"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データで訓練 --- (※5)\n",
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=100,\n",
    "    epochs=20,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=2)],\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T02:24:05.656603",
     "start_time": "2017-05-25T02:24:05.641590"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 0.367143461439\n",
      "accuracy= 0.95555555688\n"
     ]
    }
   ],
   "source": [
    "# テストデータを用いて評価する --- (※6)\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの保存\n",
    "[こちら](http://m0t0k1ch1st0ry.com/blog/2016/07/17/keras/)を参考にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T02:19:30.170548",
     "start_time": "2017-05-25T02:19:29.720804"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json_str = model.to_json()\n",
    "with open('./data/iris_mlp_model.json', 'w') as ff:\n",
    "    ff.write(model_json_str)\n",
    "model.save_weights('./data/iris_mlp_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T02:24:18.819779",
     "start_time": "2017-05-25T02:24:17.870025"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 0.186865983407\n",
      "accuracy= 0.977777777778\n"
     ]
    }
   ],
   "source": [
    "def save_learned_model(model, fldrpath):\n",
    "    model_json_str = model.to_json()\n",
    "    f_json = fldrpath + fldrpath.split(\"/\")[]os.path.splitext(fpath)[0] + \".json\"\n",
    "    with open(f_json, 'w') as ff:\n",
    "        ff.write(model_json_str)\n",
    "    \n",
    "    f_h5 = os.path.splitext(fpath)[0] + \".h5\"\n",
    "    model.save_weights(f_h5)\n",
    "\n",
    "def load_learned_model(fpath):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # モデルの読み込み\n",
    "    f_json = os.path.splitext(fpath)[0] + \".json\"\n",
    "    model = model_from_json(open(f_json, \"r\").read())\n",
    "    \n",
    "    # 学習結果の読み込み\n",
    "    f_h5 = os.path.splitext(fpath)[0] + \".h5\"\n",
    "    model.load_weights(f_h5)\n",
    "    \n",
    "    # モードの読み込み\n",
    "    f_mode = os.path.splitext(fpath)[0] + \".mode\"\n",
    "    with open(f_mode, \"rb\") as ff:\n",
    "        mode = pickle.load(ff)\n",
    "        \n",
    "    # summary = model2.summary()\n",
    "    model.compile(loss=mode[\"loss\"],\n",
    "        optimizer=mode[\"optimizer\"],\n",
    "        metrics=mode[\"metrics\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# テスト\n",
    "score = model2.evaluate(X_test, y_test, verbose=0)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所感\n",
    "テストデータが少なくても、ノードの数が多いほうが正解率が上がる？   \n",
    "ただのフィッティングの感覚でいくと、サンプル数よりも多いパラメータを求めようとしているような気がしてならないのだが、、   \n",
    "学習済みモデルの保存と読み込みの手順が、Tensorflowより多い。この辺はさらにラッパーを用意すればよいか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 為替のデータを学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T02:56:35.339503",
     "start_time": "2017-05-28T02:56:35.221568"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(X, y):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 入力層\n",
    "    model.add(Dense(512, input_shape=(X.shape[1],)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # 中間層\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # 出力層\n",
    "    model.add(Dense(y.shape[1]))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # コンパイル\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=\"rmsprop\",\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T23:13:36.025260",
     "start_time": "2017-05-25T23:13:36.018747"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = af.labeling(dclose, s, 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T23:06:49.551156",
     "start_time": "2017-05-25T23:06:49.537642"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2632,) (1128,) (2632, 3) (1128, 3)\n"
     ]
    }
   ],
   "source": [
    "close_norm = close - close.mean()\n",
    "X = close_norm / np.abs(close_norm).max()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5555)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T23:05:28.152857",
     "start_time": "2017-05-25T23:05:27.791807"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = create_model(X[:, None], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練と評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T23:05:54.424594",
     "start_time": "2017-05-25T23:05:50.252052"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データで訓練 --- (※5)\n",
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=100,\n",
    "    epochs=20,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=2)],\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T23:07:06.177443",
     "start_time": "2017-05-25T23:07:06.077365"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 1.09173293739\n",
      "accuracy= 0.394503546099\n"
     ]
    }
   ],
   "source": [
    "# テストデータを用いて評価する --- (※6)\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "closeだけではやはり40%を超えない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OHLCを利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T23:13:59.863898",
     "start_time": "2017-05-25T23:13:59.857893"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = af.labeling(dclose, s, 30, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T23:14:00.263522",
     "start_time": "2017-05-25T23:14:00.246510"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2632, 4) (1128, 4) (2632, 3) (1128, 3)\n"
     ]
    }
   ],
   "source": [
    "ohlc_mean = ohlc.mean(axis=1)\n",
    "ohlc_norm = np.zeros_like(ohlc)\n",
    "for ii in range(ohlc.shape[0]):\n",
    "    ohlc_norm[ii] = ohlc[ii] - ohlc_mean[ii]\n",
    "    ohlc_norm[ii] /= np.abs(ohlc_norm[ii]).max()\n",
    "\n",
    "X = ohlc_norm.T\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5555)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T23:14:26.021912",
     "start_time": "2017-05-25T23:14:22.457065"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = create_model(X, y)\n",
    "\n",
    "# データで訓練 --- (※5)\n",
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=100,\n",
    "    epochs=30,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=2)],\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T23:14:26.135269",
     "start_time": "2017-05-25T23:14:26.021912"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 1.0883773337\n",
      "accuracy= 0.38829787234\n"
     ]
    }
   ],
   "source": [
    "# テストデータを用いて評価する --- (※6)\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dcloseを利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T23:17:57.684042",
     "start_time": "2017-05-25T23:17:51.187212"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3008,) (752,) (3008, 3) (752, 3)\n",
      "loss= 0.94668527106\n",
      "accuracy= 0.457446808511\n"
     ]
    }
   ],
   "source": [
    "X = dclose / np.abs(dclose).max()\n",
    "y = af.labeling(close, s, 60, 2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "model = create_model(X[:,None], y)\n",
    "\n",
    "# データで訓練 --- (※5)\n",
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=100,\n",
    "    epochs=20,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=2)],\n",
    "    verbose=0)\n",
    "\n",
    "# テストデータを用いて評価する --- (※6)\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習用のデータの数が少ない？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 層を増やしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T23:19:56.806300",
     "start_time": "2017-05-25T23:19:56.783289"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(X, y):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 入力層\n",
    "    model.add(Dense(512, input_shape=(X.shape[1],)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # 中間層\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # 中間層２\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # 出力層\n",
    "    model.add(Dense(y.shape[1]))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # コンパイル\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=\"rmsprop\",\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T23:20:04.704831",
     "start_time": "2017-05-25T23:19:57.906393"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3008,) (752,) (3008, 3) (752, 3)\n",
      "loss= 0.947001878251\n",
      "accuracy= 0.456117021277\n"
     ]
    }
   ],
   "source": [
    "X = dclose / np.abs(dclose).max()\n",
    "y = af.labeling(close, s, 60, 2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "model = create_model(X[:,None], y)\n",
    "\n",
    "# データで訓練 --- (※5)\n",
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=100,\n",
    "    epochs=20,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=2)],\n",
    "    verbose=0)\n",
    "\n",
    "# テストデータを用いて評価する --- (※6)\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "時間やほかの情報もパラメータに入れるとよいのだろうが、、"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ラベリングの対象を変える\n",
    "これまではなぜかdcloseに対してラベリングを行っていた。本当になぜだろう？   \n",
    "ここでcloseに対してラベリングを行い、予測確率が上がるかどうか確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T03:10:31.590374",
     "start_time": "2017-05-28T03:10:31.560355"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(X, y):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 入力層\n",
    "    model.add(Dense(512, input_shape=(X.shape[1],)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # 中間層\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # 出力層\n",
    "    model.add(Dense(y.shape[1]))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # コンパイル\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=\"rmsprop\",\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T03:13:02.271734",
     "start_time": "2017-05-28T03:13:02.223702"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2632, 1) (1128, 1) (2632, 3) (1128, 3)\n"
     ]
    }
   ],
   "source": [
    "y = af.labeling(close, s, 60, 2)\n",
    "\n",
    "close_norm = close - close.mean()\n",
    "X = close_norm / np.abs(close_norm).max()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:,None], y, test_size=0.3, random_state=5555)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T03:13:33.620257",
     "start_time": "2017-05-28T03:13:22.466564"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 0.961993373032\n",
      "accuracy= 0.512411347518\n"
     ]
    }
   ],
   "source": [
    "model = create_model(X[:,None], y)\n",
    "\n",
    "# データで訓練 --- (※5)\n",
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=100,\n",
    "    epochs=20,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=2)],\n",
    "    verbose=0)\n",
    "\n",
    "# テストデータを用いて評価する --- (※6)\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ようやく51％まで上がったが、これが普通なのかもしれない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTMの練習\n",
    "Kerasの`LSTM`クラスを用いて、為替の時系列データを学習させてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T03:14:44.652124",
     "start_time": "2017-05-28T03:14:44.638115"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(X, y):\n",
    "    model = Sequential()\n",
    "#     model.add(Embedding(max_features, 256, input_length=maxlen))\n",
    "    model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), activation='sigmoid', recurrent_activation='hard_sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(y.shape[1]))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T03:14:47.667496",
     "start_time": "2017-05-28T03:14:47.661493"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = af.labeling(close, s, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T03:15:09.696426",
     "start_time": "2017-05-28T03:15:09.673414"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2632, 20, 1) (1128, 20, 1) (2632, 3) (1128, 3)\n"
     ]
    }
   ],
   "source": [
    "close_norm = close - close.mean()\n",
    "X = close_norm / np.abs(close_norm).max()\n",
    "X = af.timeseries(X,20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:, :, None], y, test_size=0.3, random_state=5555)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T03:16:27.602124",
     "start_time": "2017-05-28T03:15:18.394147"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = create_model(X[:, :, None], y)\n",
    "model.fit(X_train, y_train, batch_size=16, epochs=10, verbose=0)\n",
    "score = model.evaluate(X_test, y_test, batch_size=16, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T03:16:30.295140",
     "start_time": "2017-05-28T03:16:30.284134"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 1.04494662488\n",
      "accuracy= 0.419326241135\n"
     ]
    }
   ],
   "source": [
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMの方は、まだまだチューニングが必要そうである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# まとめ\n",
    "Kerasを用いると、Tensorflowの利用が楽になることが分かった。   \n",
    "また、チューニングと適切な特徴量の選択をしない限り、為替の予測はできないことも分かった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "534px",
    "left": "0px",
    "right": "1139px",
    "top": "106px",
    "width": "223px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
